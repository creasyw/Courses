* Functions

Function application (calling a function by putting a space after it and then typing out the parameters) has the highest precedence of them all. What that means for us is that these two statements are equivalent. Besides, it is a very simple example of a common pattern you will see throughout Haskell - /making basic functions that are obviously correct and then combining them into more complex functions/. This way you also avoid repetition. Functions in Haskell don't have to be in any particular order, so it doesn't matter if you define doubleMe first and then doubleUs or if you do it the other way around.

The difference between Haskell's if statement and if statements in imperative languages is that the else part is mandatory in Haskell. Another thing about the if statement in Haskell is that it is an expression. /An expression is basically a piece of code that returns a value/. Because the else is mandatory, an if statement will always return something and that's why it's an expression.

Note the ' at the end of the function name. That apostrophe doesn't have any special meaning in Haskell's syntax. It's a valid character to use in a function name. We usually use ' to either denote a strict version of a function (one that isn't lazy) or a slightly modified version of a function or a variable.

There are two noteworthy things about a function - the first is that functions can't begin with uppercase letters. The second thing is that when a function doesn't take any parameters, we usually say it's a definition (or a name). Because we can't change what names (and functions) mean once we've defined them.

* List and tuples

In Haskell, lists are a homogenous data structure. It stores several elements of the same type. That means that we can have a list of integers or a list of characters but we can't have a list that has a few integers and then a few characters.

A common task is putting two lists together. *Watch out when repeatedly using the =++= operator on long strings*. This is done by using the =++= operator. For list concatination, Haskell will walk through the whole list at the left side of the =++=. So, /put the longer one at the right will be a good practice/. Or, use the append operation =:= to put the new element at the head of the original list.

Two lists can be compared! (if the stuff they contain can be compared) The comparison performs in a lexicographical order. If you want to get an element out of a list by index, use !!. The indices start at 0. In haskell, =head= and =tail= likes the =car= and =cons= in Racket - the former returns the first item of the list while the latter returns the /list/ without the first item.

In some ways, tuples are like lists â€” they are a way to store several values into a single value. However, there are a few fundamental differences. A list of numbers is a list of numbers. That's its type and it doesn't matter if it has only one number in it or an infinite amount of numbers. Tuples, however, are used when you know exactly how many values you want to combine and its type depends on how many components it has and the types of the components. They are denoted with parentheses and their components are separated by commas. Another key difference is that they don't have to be homogenous. Unlike a list, a tuple can contain a combination of several types.

#+begin_src haskell
ghci> let rightTriangles' = [ (a,b,c) | c <- [1..10], b <- [1..c], a <- [1..b], a^2 + b^2 == c^2, a+b+c == 24]
ghci> rightTriangles'
[(6,8,10)]
#+end_src

- this is just so cool! It has nested loops and conditions in a single list comprehension.

* Types and Typeclasses

Haskell has a static type system. The type of every expression is known at compile time, which leads to safer code. Furthermore, Haskell has type inference. A type is a kind of label that every expression has. It tells us in which category of things that expression fits.

Functions also have types. When writing our own functions, we can choose to give them an explicit type declaration. This is generally considered to be good practice except when writing very short functions.

Int and Integer both stand for the type of integers. The difference is that the latter one is /not bounded/.

Here's a simple function that takes three integers and adds them together:

#+begin_src haskell
addThree :: Int -> Int -> Int -> Int
addThree x y z = x + y + z
#+end_src

This signature makes it possible to partially apply input parameters to a function and use it to generate new functions.

A typeclass can be regarded as an interface that define some behavior. If a type is a part of a typeclass, that means that it supports and implement the behavior the typeclass describes. (it is the exactly what an interface does in Golang - it has contract on the behavior of the data that a function receives or generates.) However, it /feels/ like a wider implication. For example,

#+begin_src haskell
Prelude> :t read
read :: Read a => String -> a
Prelude> read "4" + 0
4
Prelude> read "4"
*** Exception: Prelude.read: no parse
Prelude>
Prelude> read "4" :: Int
4
#+end_src

The signature of =read=  can generate a typeclass, which if there is no other operation (e.g. =+0=) to help the compiler infers its type, the compilation fails unless we tell it explicitly about the type.

Most expressions are such that the compiler can infer what their type is by itself. But sometimes, the compiler doesn't know whether to return a value of type Int or Float for an expression like read "5". To see what the type is, Haskell would have to actually evaluate read "5". But since Haskell is a statically typed language, it has to know all the types before the code is compiled (or in the case of GHCI, evaluated). So we have to tell Haskell: "Hey, this expression should have this type, in case you don't know!".

* Syntax in Functions

The pattern matching in Haskell is in a whole new level and fucking crazy...

#+begin_src haskell
lucky :: (Integral a) => a -> String
lucky 7 = "LUCKY NUMBER SEVEN!"
lucky x = "Sorry, you're out of luck, pal!"
#+end_src

The pattern matching does not include the keyword "break", and will /always exit after executing any one of the branches/. The recommanded practice of writing cases from specific to general in LISP becomes mandatory here, because /it *sequentially* checks all patterns from the first to the last/. Besides, there should always be a "catch-all" pattern at the end of the matching. Without it, it is possible to terminate the program while running when it fails to do the pattern matching.

Another important use of pattern matching is with the list -

#+begin_src haskell
>> x:y:z:zs = [1,2,3,4,5,6,7]
>> x
  1
>> zs
  [4,5,6,7]
#+end_src

Note that if you want to bind to several variables (even if one of them is just =_= and doesn't actually bind at all), we have to surround them in parentheses.

#+begin_src haskell
length' []     = 0
length' (x:xs) = 1 + length' xs
#+end_src

There's also a thing called /as patterns/. Those are a handy way of breaking something up according to a pattern and binding it to names whilst still keeping a reference to the whole thing. You do that by putting a name and an @ in front of a pattern. For instance, the pattern =xs@(x:y:ys)=. This pattern will match exactly the same thing as =x:y:ys= but you can easily get the whole list via =xs= instead of repeating yourself by typing out =x:y:ys= in the function body again.

Whereas patterns are a way of making sure a value conforms to some form and deconstructing it, guards are a way of testing whether some property of a value (or several of them) are true or false. That sounds a lot like an if statement and it's very similar. The thing is that guards are a lot more readable when you have several conditions and they play really nicely with patterns.

Although guards look similar to pattern matching, but they are fundamentally different. Every expression behind the guards will return a boolean result, which in turn dictate whether this branch will be executed. Furthermore, any condition within guards could use pattern matching to disassemble something, the result of the matching is either success or failed.

The names we define in the =where= section of a function are only visible to that function, so we don't have to worry about them polluting the namespace of other functions. Notice that all the names are aligned at a single column. If we don't align them nice and proper, Haskell gets confused because then it doesn't know they're all part of the same block. =where= bindings aren't shared across function bodies of different patterns. If you want several patterns of one function to access some shared name, you have to define it globally. =where= bindings can also be nested. /It's a common idiom to make a function and define some helper function in its =where= clause and then to give those functions helper functions as well, each with its own =where= clause/.

Very similar to =where= bindings are =let= bindings. Where bindings are a syntactic construct that let you bind to variables at the end of a function and the whole function can see them, including all the guards. =Let= bindings let you bind to variables anywhere and are expressions themselves, but are very local, so they don't span across guards. Just like any construct in Haskell that is used to bind values to names, let bindings can be used for pattern matching.

The difference is that =let= bindings are expressions themselves, =where= bindings are just syntactic constructs. That is, /for the sake of pattern matching, let bindings cannot be used cross bars, since they are expressions and are firely local in the scope/. Some people prefer =where= bindings because the names come after the function they're being used in. That way, the function body is closer to its name and type declaration and to some that's more readable. (some people also include me...)

Many imperative languages (C, C++, Java, etc.) have case syntax and if you've ever programmed in them, you probably know what it's about. It's about taking a variable and then executing blocks of code for specific values of that variable and then maybe including a catch-all block of code in case the variable has some value for which we didn't set up a case.

Haskell takes that concept and one-ups it. Like the name implies, case expressions are, well, expressions, much like if else expressions and let bindings. Not only can we evaluate expressions based on the possible cases of the value of a variable, we can also do pattern matching. Taking a variable, pattern matching it, evaluating pieces of code based on its value - /pattern matching on parameters in function definitions is actually just syntactic sugar for case expressions/. (Yes... it is a whole new level..)
