* Making our own types and typeclasses

  #+begin_quote
The type feels like a class in an OOP language. It contains native or pre-defined data structures, and has constructors by default. It also needs to be "inherited" from an existing typeclass so that the compiler could leverage the interface and (existing) default functions of that typeclass to perform the regular operations on the new type. Then, we can define functions that do operations with the newly defined type.
  #+end_quote

  #+begin_src haskell
data Shape = Circle Float Float Float | Rectangle Float Float Float Float deriving (Show)
  #+end_src

In the example above, the type is =Shape= and the constructors are =Circle= and =Rectangle=.

#+begin_src haskell
Prelude> data Shape = Circle Float Float Float | Rectangle Float Float Float Float deriving (Show)
Prelude> :t Circle
Circle :: Float -> Float -> Float -> Shape
Prelude> :info Shape
data Shape
  = Circle Float Float Float | Rectangle Float Float Float Float
        -- Defined at <interactive>:7:1
instance [safe] Show Shape -- Defined at <interactive>:7:85
#+end_src

If we wanted to export the functions and types that we defined here in a module, we could start it off like this:

#+begin_src haskell
module Shapes
( Point(..)
, Shape(..)
, surface
, nudge
, baseCircle
, baseRect
) where
#+end_src

By doing =Shape(..)=, we exported all the value constructors for =Shape=, so that means that whoever imports our module can make shapes by using the =Rectangle= and =Circle= value constructors. It's the same as writing =Shape(Rectangle, Circle)=.

We could also opt not to export any value constructors for =Shape= by just writing Shape in the export statement. /That way, someone importing our module could only make shapes by using the auxilliary functions =baseCircle= and =baseRect=/. =Data.Map= uses that approach. You can only make a mapping by using one of the auxilliary functions like =Map.fromList=. Remember, *value constructors are just functions that take the fields as parameters and return a value of some type (like =Shape)= as a result*. So when we choose not to export them, we just prevent the person importing our module from using those functions, but if some other functions that are exported return a type, we can use them to make values of our custom data types. /Not exporting the value constructors of a data types makes them more abstract in such a way that we hide their implementation. Also, whoever uses our module can't pattern match against the value constructors/ - that is called intentional design choice...

#+begin_src haskell
data Person = Person
                { firstName   :: String
                , lastName    :: String
                , age         :: Int
                , height      :: Float
                , phoneNumber :: String
                , flavor      :: String
                }
  deriving (Show)
#+end_src

So instead of just naming the field types one after another and separating them with spaces, we use curly brackets. First we write the name of the field, for instance, firstName and then we write a double colon =::= and then we specify the type. The resulting data type is exactly the same. The main benefit of this is that it creates functions that lookup fields in the data type. By using record syntax to create this data type, Haskell automatically made these functions: firstName, lastName, age, height, phoneNumber and flavor. There's another benefit to using record syntax. When we derive Show for the type, it displays it differently if we use record syntax to define and instantiate the type.

/Using type parameters is very beneficial, but only when using them makes sense/. Usually we use them when our data type would work regardless of the type of the value it then holds inside it, like with our =Maybe a= type. /If our type acts as some kind of box, it's good to use them/.

We usually use type parameters when the type that's contained inside the data type's various value constructors isn't really that important for the type to work. A list of stuff is a list of stuff and it doesn't matter what the type of that stuff is, it can still work. If we want to sum a list of numbers, we can specify later in the summing function that we specifically want a list of numbers. Same goes for Maybe. Maybe represents an option of either having nothing or having one of something. It doesn't matter what the type of that something is.

Another example of a parameterized type that we've already met is =Map k v= from =Data.Map=. The =k= is the type of the keys in a map and the v is the type of the values. This is a good example of where type parameters are very useful. Having maps parameterized enables us to have mappings from any type to any other type, as long as the type of the key is part of the Ord typeclass. If we were defining a mapping type, we could add a typeclass constraint in the data declaration:

#+begin_src haskell
data (Ord k) => Map k v = ...
#+end_src

However, it's a very strong convention in Haskell /to never add typeclass constraints in data declarations/. Why? Well, because we don't benefit a lot, but we end up writing more class constraints, even when we don't need them. If we put or don't put the Ord k constraint in the data declaration for Map k v, we're going to have to put the constraint into functions that assume the keys in a map can be ordered. But if we don't put the constraint in the data declaration, we don't have to put (Ord k) => in the type declarations of functions that don't care whether the keys can be ordered or not. So don't put type constraints into data declarations even if it seems to make sense, because you'll have to put them into the function type declarations either way.

#+begin_src haskell
data Vector a = Vector a a a deriving (Show)

vplus :: (Num t) => Vector t -> Vector t -> Vector t
(Vector i j k) `vplus` (Vector l m n) = Vector (i+l) (j+m) (k+n)

vectMult :: (Num t) => Vector t -> t -> Vector t
(Vector i j k) `vectMult` m = Vector (i*m) (j*m) (k*m)

scalarMult :: (Num t) => Vector t -> Vector t -> t
(Vector i j k) `scalarMult` (Vector l m n) = i*l + j*m + k*n
#+end_src

Once again, it's very important to distinguish between the type constructor and the value constructor. When declaring a data type, the part before the === is the type constructor and the constructors after it (possibly separated by =|= 's) are value constructors. Giving a function a type of =Vector t t t -> Vector t t t -> t= would be wrong, because we have to put types in *type* declaration and the vector type constructor takes only one parameter, whereas the value constructor takes three. Let's play around with our vectors.

/A typeclass is a sort of an interface that defines some behavior. A type can be made an instance of a typeclass if it supports that behavior/. Typeclasses are more like interfaces. We don't make data from typeclasses. Instead, we first make our data type and then we think about what it can act like. If it can act like something that can be equated, we make it an instance of the Eq typeclass. If it can act like something that can be ordered, we make it an instance of the =Ord= typeclass.

We can derive instances for the =Ord= type class, which is for types that have values that can be ordered. /If we compare two values of the same type that were made using different constructors, the value which was made with a constructor that's defined first is considered smaller/. For instance, consider the =Bool= type, which can have a value of either =False= or =True=.

Previously, we mentioned that when writing types, the [Char] and String types are equivalent and interchangeable. That's implemented with type synonyms. Type synonyms don't really do anything per se, they're just about giving some types different names so that they make more sense to someone reading our code and documentation. Giving the String type synonyms is something that Haskell programmers do when they want to convey more information about what strings in their functions should be used as and what they represent.

(The typeclass is mind-boggling complex... it is able to create new data type as well as having abstractions upon data types. Just to make things worse, the data types can also be recursive.)

So far, we've seen that =Maybe a= was mostly used to represent the results of computations that could have either failed or not. But somtimes, =Maybe a= isn't good enough because Nothing doesn't really convey much information other than that something has failed. That's cool for functions that can fail in only one way or if we're just not interested in how and why they failed. A =Data.Map= lookup fails only if the key we were looking for wasn't in the map, so we know exactly what happened. However, when we're interested in how some function failed or why, we usually use the result type of =Either a b=, where =a= is some sort of type that can tell us something about the possible failure and =b= is the type of a successful computation. Hence, errors use the Left value constructor while results use Right.


#+begin_src haskell
import qualified Data.Map as Map

data Either a b = Left a | Right b deriving (Eq, Ord, Read, Show)
data LockerState = Taken | Free deriving (Show, Eq)
type Code = String
type LockerMap = Map.Map Int (LockerState, Code)

-- fuck the `either`!
lockerLookup :: Int -> LockerMap -> Either String Code
lockerLookup lockerNumber map =
    case Map.lookup lockerNumber map of
        Nothing -> Left $ "Locker number " ++ show lockerNumber ++ " doesn't exist!"
        Just (state, code) -> if state /= Taken
                                then Right code
                                else Left $ "Locker " ++ show lockerNumber ++ " is already taken!"
#+end_src

Defining recursive data structure

#+begin_src haskell
-- This typeclass defines three data structures =EmptyTree=, =Node=, and =Tree=
data Tree a = EmptyTree | Node a (Tree a) (Tree a) deriving (Show, Read, Eq)

-- Similar to recursive function, it starts from the edge case
singleton :: a -> Tree a
singleton x = Node x EmptyTree EmptyTree

-- This is interesting
-- A tree is defined as (Node, Tree, Tree), which is =Node a left right= in the
-- follow function, where =left= and =right= are two trees
treeInsert :: (Ord a) => a -> Tree a -> Tree a
treeInsert x EmptyTree = singleton x
treeInsert x (Node a left right)
    | x == a = Node x left right
    | x < a  = Node a (treeInsert x left) right
    | x > a  = Node a left (treeInsert x right)

treeElem :: (Ord a) => a -> Tree a -> Bool
treeElem x EmptyTree = False
treeElem x (Node a left right)
    | x == a = True
    | x < a  = treeElem x left
    | x > a  = treeElem x right
#+end_src

Typeclasses are like interfaces. A typeclass defines some behavior (like comparing for equality, comparing for ordering, enumeration) and then types that can behave in that way are made instances of that typeclass. The behavior of typeclasses is achieved by defining functions or just type declarations that we then implement. So when we say that a type is an instance of a typeclass, we mean that we can use the functions that the typeclass defines with that type. Besides, we can also make typeclasses that are subclasses of other typeclasses. (the first part smells very similar to the interface in Golang, but the 2nd part makes it more powerful than its counterpart in Golang.)

Most of the times, class constraints in class declarations are used for making a typeclass a subclass of another typeclass and class constraints in instance declarations are used to express requirements about the contents of some type. When making instances, if you see that a type is used as a concrete type in the type declarations (like the =a= in =a -> a -> Bool=), you have to supply type parameters and add parentheses so that you end up with a concrete type.

#+begin_src haskell
data TrafficLight = Red | Yellow | Green

-- here it assumes the =Eq= is not a native typeclass, otherwise, it can
-- directly use =derive=. If it is not native, the type has to be initiated
-- via =instance= as if initiating a class in OOP.
-- I feel this is a bad naming.
instance Eq TrafficLight where
    Red == Red = True
    Green == Green = True
    Yellow == Yellow = True
    _ == _ = False

instance Show TrafficLight where
    show Red = "Red light"
    show Yellow = "Yellow light"
    show Green = "Green light"
#+end_src

=data= means that we're defining a new data type. The parts after the === are *value constructors*. They specify the different values that this type can have. A *value constructor* can take some values parameters and then produce a new value. In a similar manner, *type constructors* can take types as parameters to produce new types. =class= is for defining new typeclasses and =instance= is for making our types instances of typeclasses.

If you want to see what the instances of a typeclass are, just do =:info YourTypeClass= in GHCI. So typing =:info= Num will show which functions the typeclass defines and it will give you a list of the types in the typeclass. =:info= works for types and type constructors too. If you do =:info Maybe=, it will show you all the typeclasses that =Maybe= is an instance of. Also =:info= can show you the type declaration of a function. I think that's pretty cool. :)

#+begin_src haskell
ghci> :k Int
Int :: *

ghci> :k Maybe
Maybe :: * -> *
#+end_src

A =*= means that the type is a concrete type. A concrete type is a type that doesn't take any type parameters and values can only have types that are concrete types.

#+begin_src hasekll
-- It is short for =:kind= for a type, and like =:t= (=:type=) for function
ghci> :k Int
Int :: *
#+end_src

In this section, we took a good look at how type parameters work and kind of formalized them with kinds, just like we formalized function parameters with type declarations. We saw that there are interesting parallels between functions and type constructors. They are, however, two completely different things. When working on real Haskell, you usually won't have to mess with kinds and do kind inference by hand like we did now. Usually, you just have to partially apply your own type to * -> * or * when making it an instance of one of the standard typeclasses, but it's good to know how and why that actually works. It's also interesting to see that types have little types of their own. Again, you don't really have to understand everything we did here to read on, but if you understand how kinds work, chances are that you have a very solid grasp of Haskell's type system.

And now, we're going to take a look at the *Functor typeclass*, which is /basically for things that can be mapped over/.

#+begin_src haskell
class Functor f where
      fmap :: (a -> b) -> f a -> f b

instance Functor [] where
      fmap = map
#+end_src

The =f= is not a concrete type (a type that a value can hold, like =Int=, =Bool= or =Maybe String=), but a /type constructor/ that takes one type parameter. A quick refresher example: =Maybe Int= is a concrete type, but =Maybe= is a type constructor that takes one type as the parameter. Anyway, we see that =fmap= takes a function from one type to another and a functor applied with one type and returns a functor applied with another type. Functor wants a type constructor that takes one type and not a concrete type.

#+begin_src haskell
λ> :info fmap
class Functor (f :: * -> *) where
  fmap :: (a -> b) -> f a -> f b
  ...
  	-- Defined in ‘GHC.Base’
λ> :info Functor
class Functor (f :: * -> *) wher
  fmap :: (a -> b) -> f a -> f b
  (<$) :: a -> f b -> f a
  {-# MINIMAL fmap #-}
  	-- Defined in ‘GHC.Base’
instance Functor (Either a) -- Defined in ‘Data.Either’
instance Functor [] -- Defined in ‘GHC.Base’
instance Functor Maybe -- Defined in ‘GHC.Base’
instance Functor IO -- Defined in ‘GHC.Base’
instance Functor ((->) r) -- Defined in ‘GHC.Base’
instance Functor ((,) a) -- Defined in ‘GHC.Base’
#+end_src

Since for lists, =fmap= is just =map=, we get the same results when using them on lists. /Types that can act like a box can be functors/. You can think of a list as a box that has an infinite amount of little compartments and they can all be empty, one can be full and the others empty or a number of them can be full. So, what else has the properties of being like a box? For one, the =Maybe a= type.

/Type constructors/ take other types as parameters to eventually produce concrete types. We've seen that type constructors can be partially applied (=Either String= is a type that takes one type and produces a concrete type, like =Either String Int=), just like functions can.

** Summary

- =data= defines *type*, which has *type constructor* at the left side of the equation and *value constructor* at the right side of the constructor. More often than not, it also have =derive= which helps defines the basic behaviors of this type based on existing *typeclass*.
- =type= is type synonyms. It can use basic types to construct a compound and give a short name.
- =class= is to define =typeclass=.
- =instance= is to define the customized behavior of the specific *type* under given *typeclass*, /if we choose not to use the =derive=/. It is especially useful to make the newly added type could be apply to =Functor= so that we could use =fmap= to "batch process the data of this type.

* Input and Output

Whereas in imperative languages you usually get things done by giving the computer a series of steps to execute, /functional programming is more of defining what stuff is/. /The only thing a function can do in Haskell is give us back some result based on the parameters we gave it/. While functions being unable to change state is good because it helps us reason about our programs, there's one problem with that. (I guess it is the same reason that everything about the I/O operatin is weird...) Haskell actually has a really clever system for dealing with functions that have side-effects that neatly separates the part of our program that is pure and the part of our program that is impure, which does all the dirty work like talking to the keyboard and the screen. With those two parts separated, we can still reason about our pure program and take advantage of all the things that purity offers, like laziness, robustness and modularity while efficiently communicating with the outside world.

#+begin_src haskell
ghci> :t putStrLn
putStrLn :: String -> IO ()
ghci> :t putStrLn "hello, world"
putStrLn "hello, world" :: IO ()
#+end_src

An I/O action is something that, when performed, will carry out an action with a side-effect (that's usually either reading from the input or printing stuff to the screen) and will also contain some kind of return value inside it. Printing a string to the terminal doesn't really have any kind of meaningful return value, so a dummy value of =()= is used.

If we're taking data out of an I/O action, we can only take it out when we're inside another I/O action. This is how Haskell manages to neatly separate the pure and impure parts of our code. =getLine= is in a sense impure because its result value is not guaranteed to be the same when performed twice. That's why it's sort of tainted with the IO type constructor and we can only get that data out in I/O code. And /because I/O code is tainted too, any computation that depends on tainted I/O data will have a tainted result/. If we want to deal with impure data, we have to do it in an impure environment. So the taint of impurity spreads around much like the undead scourge and *it's in our best interest to keep the I/O parts of our code as small as possible*.

Remember, *to get the value out of an I/O action, you have to perform it inside another I/O action by binding it to a name with =<-=*.

/I/O actions will only be performed when they are given a name of main or when they're inside a bigger I/O action that we composed with a do block/. We can also use a do block to glue together a few I/O actions and then we can use that I/O action in another do block and so on. *Either way, they'll be performed only if they eventually fall into main* (this really fucks up things).

#+begin_src haskell
import Data.Char

main = do
    putStrLn "What's your first name?"
    -- bind the IO String to a regular String
    firstName <- getLine
    -- bind the IO String to a regular String
    putStrLn "What's your last name?"
    lastName <- getLine
    -- operations using pure functions with pure data type to get another pure data type
    let bigFirstName = map toUpper firstName
        bigLastName = map toUpper lastName
    -- feed the pure data types into another IO function
    putStrLn $ "hey " ++ bigFirstName ++ " " ++ bigLastName ++ ", how are you?"
#+end_src

=<-= is (for now) for performing I/O actions and binding their results to names. =map toUpper firstName=, however, isn't an I/O action. It's a /pure/ expression in Haskell. So use =<-= when you want to bind results of I/O actions to names and you can use let bindings to bind pure expressions to names. Had we done something like =let firstName = getLine=, we would have just called the =getLine= I/O action a different name and we'd still have to run it through a =<-= to perform it.

*The return in Haskell is really nothing like the return in most other languages*. In Haskell (in I/O actions specifically), it makes an I/O action out of a pure value. If you think about the box analogy from before, it takes a value and wraps it up in a box. The resulting I/O action doesn't actually do anything, it just has that value encapsulated as its result. So in an I/O context, =return "haha"= will have a type of =IO String=, because we needed some I/O action to carry out in the case of an empty input line. That's why we just made a bogus I/O action that doesn't do anything by writing =return ()=. (so, is it like =yield= for I/O?...) Using =return= doesn't cause the I/O do block to end in execution or anything like that.

=print= takes a value of any type that's an instance of =Show= (meaning that we know how to represent it as a string), calls =show= with that value to stringify it and then outputs that string to the terminal. Basically, it's just =putStrLn . show=. It first runs =show= on a value and then feeds that to =putStrLn=, which returns an I/O action that will print out our value.

The =when= function is found in =Control.Monad= (to get access to it, do =import Control.Monad=). It's interesting because in a do block it looks like a control flow statement, but it's actually a normal function. It takes a boolean value and an I/O action if that boolean value is =True=, it returns the same I/O action that we supplied to it. However, if it's =False=, it returns the =return ()= action, so an I/O action that doesn't do anything.

#+begin_src haskell
import Control.Monad

main = do
    c <- getChar
    when (c /= ' ') $ do
        putChar c
        main
#+end_src

#+begin_src haskell
import Control.Monad

main = do
    -- forM get a list of IO (Monad) types of data.
    -- We can also use =mapM=. =forM= is for readability. It puts the function in the end of the block
    -- Note that =forM= expects ONE anonymous function, that's why another =do= is here to chain multiple IO commands
    colors <- forM [1,2,3,4] (\a -> do
        putStrLn $ "Which color do you associate with the number " ++ show a ++ "?"
        color <- getLine
        -- return change the pure data type into an IO type
        return color)
    putStrLn "The colors that you associate with 1, 2, 3 and 4 are: "
    mapM putStrLn colors
#+end_src

I/O actions are values much like any other value in Haskell. We can pass them as parameters to functions and functions can return I/O actions as results. What's special about them is that if they fall into the main function (or are the result in a GHCI line), they are performed. Each I/O action can also encapsulate a result with which it tells you what it got from the real world.

** File and Streams

   #+begin_src haskell
main = interact $ unlines . filter ((<10) . length) . lines
   #+end_src

=interact= can be used to make programs that are piped some contents into them and then dump some result out or it can be used to make programs that appear to take a line of input from the user, give back some result based on that line and then take another line and so on. There isn't actually a real distinction between the two, it just depends on how the user is supposed to use them. (It feels really like a saver - as long as the concatenated function has a signature of =String -> String=, it can be used with the =interact=. As a result, the heavy-lifting operations can all be positioned in a purely functional environment.)

=hGetContents= takes a =Handle=, so it knows which file to get the contents from and returns an =IO String= — an I/O action that holds as its result the contents of the file. This function is pretty much like =getContents=. The only difference is that =getContents= will automatically read from the standard input (that is from the terminal), whereas =hGetContents= takes a file handle which tells it which file to read from. In all other respects, they work the same. And just like =getContents=, =hGetContents= won't attempt to read the file at once and store it in memory, but it will read it as needed. That's really cool because we can treat contents as the whole contents of the file, but it's not really loaded in memory. So if this were a really huge file, doing =hGetContents= wouldn't choke up our memory, but it would read only what it needed to from the file, when it needed to.

We can also use =hFlush=, which is a function that takes a handle and returns an I/O action that will flush the buffer of the file associated with the handle. When we're doing line-buffering, the buffer is flushed after every line. When we're doing block-buffering, it's after we've read a chunk. It's also flushed after closing a handle. That means that when we've reached a newline character, the reading (or writing) mechanism reports all the data so far. But we can use =hFlush= to force that reporting of data that has been read so far. After flushing, the data is available to other programs that are running at the same time.

*Haskell is a pure functional language. What that means is that it has referential transparency. What THAT means is that a function, if given the same parameters twice, must produce the same result twice*. That's really cool because /it allows us to reason differently about programs and it enables us to defer evaluation until we really need it/. However, this makes it a bit tricky for getting random numbers.

/Haskell's laziness allows us to exchange the for and while loops of other languages for filtering and mapping over lists, because evaluation will only happen once it really needs to, so things like infinite lists (and even infinite lists of infinite lists!) are no problem for us/. That's why lists can also be used to represent streams, either when reading from the standard input or when reading from files. We can just open a file and read it as a string, even though it will only be accessed when the need arises.

/Whenever you need better performance in a program that reads a lot of data into strings, give bytestrings a try, chances are you'll get some good performance boosts with very little effort on your part. I usually write programs by using normal strings and then convert them to use bytestrings if the performance is not satisfactory./

Haskell has a very good type system. Algebraic data types allow for types like =Maybe= and =Either= and we can use values of those types to represent results that may be there or not. In C, returning, say, -1 on failure is completely a matter of convention. It only has special meaning to humans. If we're not careful, we might treat these abnormal values as ordinary ones and then they can cause havoc and dismay in our code. Haskell's type system gives us some much-needed safety in that aspect. A function =a -> Maybe b= clearly indicates that it it may produce a =b= wrapped in =Just= or that it may return =Nothing=. The type is different from just plain =a -> b= and if we try to use those two functions interchangeably, the compiler will complain at us.

** Command line arguments

   #+begin_src haskell
import System.Environment
import Data.List

main = do
   args <- getArgs
   progName <- getProgName
   putStrLn "The arguments are:"
   -- the loop can be achieved by either recursion or map/filter
   -- in this case, mapM is the map for the IO operations
   mapM putStrLn args
   putStrLn "The program name is:"
   putStrLn progName
   #+end_src

** Exceptions

Despite having expressive types that support failed computations, Haskell still has support for exceptions, because they make more sense in I/O contexts. A lot of things can go wrong when dealing with the outside world because it is so unreliable.

Earlier, we talked about how we should spend as little time as possible in the I/O part of our program. /The logic of our program should reside mostly within our pure functions, because their results are dependant only on the parameters that the functions are called with/. *When dealing with pure functions, you only have to think about what a function returns, because it can't do anything else*. This makes your life easier. Even though doing some logic in I/O is necessary (like opening files and the like), it should preferably be kept to a minimum. *Pure functions are lazy by default, which means that we don't know when they will be evaluated and that it really shouldn't matter*. However, /once pure functions start throwing exceptions, it matters when they are evaluated. That's why we can only catch exceptions thrown from pure functions in the I/O part of our code/. And that's bad, because we want to keep the I/O part as small as possible. However, if we don't catch them in the I/O part of our code, our program crashes. The solution? *Don't mix exceptions and pure code. Take advantage of Haskell's powerful type system and use types like =Either= and =Maybe= to represent results that may have failed*.

* Functionally Solving Problems

It really helps to first think what the type declaration of a function should be before concerning ourselves with the implementation and then write it down. In Haskell, a function's type declaration tells us a whole lot about the function, due to the very strong type system.

we're going to solve a problem in three steps:

1. Forget Haskell for a minute and think about how we'd solve the problem by hand
2. Think about how we're going to represent our data in Haskell
3. Figure out how to operate on that data in Haskell so that we produce at a solution

* Functors, Applicative Functors and Monoids

** Functors redux

/Haskell's combination of purity, higher order functions, parameterized algebraic data types, and typeclasses allows us to implement polymorphism on a much higher level than possible in other languages/. *Typeclasses are open*, which means that we can define our own data type, think about what it can act like and connect it with the typeclasses that define its behaviors. Because of that and because of Haskell's great type system that allows us to know a lot about a function just by knowing its type declaration, /we can define typeclasses that define behavior that's very general and abstract/. (Right... _*everything starts from a typeclass*_)

_Functors are things that can be mapped over_, like lists, =Maybe= s, trees, and such. In Haskell, they're described by the typeclass Functor, which has only one typeclass method, namely =fmap=, which has a type of =fmap :: (a -> b) -> f a -> f b=. It says:

1. give me a function that takes an =a= and returns a =b=, and
2. a box with an =a= (or several of them) inside it and I'll give you a box with a =b= (or several of them) inside it.

It kind of /applies the function to the element inside the box/. A more correct term for what a functor is would be /computational context/. The context might be that the computation can have a value or it might have failed (Maybe and Either a) or that there might be more values (lists), stuff like that.

#+begin_src haskell
-- the =f= is the "computational context" mentioned above.
-- it means: the functor towards a context is that it receives a function
-- derives =a= to =b=, so that the context with =a= in it becomes the context
-- with =b= in it
λ> :t fmap
fmap :: Functor f => (a -> b) -> f a -> f b
#+end_src


(_this is something that might be wrong_... the reason we want to make a type constructor an instance of Functor is to make this constructor a "computational context" that can be extracted by =fmap= so that the construction can be re-applied from =a= to =b=. That is, if we've had the new type that is contructed with basic type =a=, then =fmap= comes handy to make the same construction with =b= along with some internal relationship that we want to impose as =(a -> b)=.)

If we want to make a type constructor an instance of =Functor=, it has to have a kind of =* -> *=, which means that it /has to take exactly one concrete type as a type parameter/. For example, =Maybe= can be made an instance because it takes one type parameter to produce a concrete type, like =Maybe Int= or =Maybe String=. If a type constructor takes two parameters, like =Either=, we have to /partially apply the type constructor until it only takes one type parameter/. So we can only write =instance Functor (Either a) where= and then if we imagine that =fmap= is only for =Either a=, it would have a type declaration of =fmap :: (b -> c) -> Either a b -> Either a c=.

#+begin_src haskell
instance Functor IO where
    fmap f action = do
        result <- action
        return (f result)
#+end_src

The result of mapping something over an I/O action will be an I/O action, so right off the bat we use =do= syntax to glue two actions and make a new one. In the implementation for =fmap=, we make a new I/O action that first performs the original I/O action and calls its result =result=. Then, we do =return (f result)=. =return= is a function that /makes an I/O action that doesn't do anything but only presents something as its result/. (In other words, =fmap= is the way for Haskell to get around the inpurity of I/O to apply a "pure" function to the data within the "inpure" I/O box.)

If we look at what =fmap='s type would be if it were limited to =IO=, it would be =fmap :: (a -> b) -> IO a -> IO b=. =fmap= takes a function and an I/O action and returns a new I/O action that's like the old one, except that the function is applied to its contained result. /If you ever find yourself binding the result of an I/O action to a name, only to apply a function to that and call that something else/ (yes, it almost killed me...), consider using =fmap=, because it looks *prettier* (seriously?). If you want to apply multiple transformations to some data inside a functor, /you can declare your own function at the top level/, make a lambda function or ideally, use function composition.

#+begin_src haskell
import Data.Char
import Data.List

-- this is actually another way to abstract the "pure" function out of the impure IO action
main = do line <- fmap (intersperse '-' . reverse . map toUpper) getLine
          putStrLn line
#+end_src

#+begin_src haskell
instance Functor ((->) r) where
    fmap f g = (\x -> f (g x))
#+end_src

What we get now is =fmap :: (a -> b) -> (r -> a) -> (r -> b)=. /Mapping one function over a function has to produce a function/, just like mapping a function over a =Maybe= has to produce a =Maybe= and mapping a function over a list has to produce a list. What does the type =fmap :: (a -> b) -> (r -> a) -> (r -> b)= for this instance tell us? Well, we see that it takes a function from =a= to =b= and a function from =r= to =a= and returns a function from =r= to =b=. /It is the same as Function composition/! We pipe the output of =r -> a= into the input of =a -> b= to get a function =r -> b=, (It also means the second function =r -> a= first applies to the input variable, which is missing in this signature, and then =a -> b= applies. /It also means we can use function to apply not only to data but also to another function/. And, *it also means the function composition =.= is a functor*.

You can think of =fmap= as either _a function that takes a function and a functor and then maps that function over the functor_, or you can think of it as _a function that takes a function and lifts that function so that it operates on functors_. Both views are correct and in Haskell, equivalent.

*Functor laws* (what can be categorized as "computational context"):

1. /Persistency (immutability)/: if we map the =id= function over a functor, the functor that we get back should be the same as the original functor. (the context does not change after applying a function)
2. /Accept function composition/: composing two functions and then mapping the resulting function over a functor should be the same as first mapping one function over the functor and then mapping the other one. Formally written, that means that =fmap (f . g) = fmap f . fmap g=. Or to write it in another way, for any functor =F=, the following should hold: =fmap (f . g) F = fmap f (fmap g F)=. (the sequence of the functions has no effect on the context that they apply to)

/Functions in Haskell are curried by default/, which means that a function that seems to take several parameters actually takes just one parameter and returns a function that takes the next parameter and so on. This mechanism is what enables us to partially apply functions by just calling them with too few parameters, which results in functions that we can then pass on to other functions. /Normal functors support mapping normal functions over existing functors. What if we want to take out the function from a curried functor and then map it to another functor/. In other words, with normal functors, you can just map a function over a functor and then you can't get the result out in any general way, /even if the result is a partially applied function/. Applicative functors, on the other hand, /allow you to operate on several functors with a single function/.

If we know that a type obeys both laws, we can make certain assumptions about how it will act. /If a type obeys the functor laws, we know that calling fmap on a value of that type will only map the function over it, nothing more/. *This leads to code that is more abstract and extensible*, because we can use laws to /reason about behaviors that any functor should have and make functions that operate reliably on any functor/ (these are two main concerns as well as advantages of this language mentioned throughout the book).

** Applicative functors

=Applicative= typeclass, which lies in the =Control.Applicative= module, comes into picture for it. It defines two methods, =pure= and =<*>=. It doesn't provide a default implementation for any of them, so we have to define them both if we want something to be an applicative functor. (this is really sick...)

#+begin_src haskell
ghci> let a = fmap (*) [1,2,3,4]
ghci> :t a
a :: [Integer -> Integer]
ghci> fmap (\f -> f 9) a
[9,18,27,36]
#+end_src

#+begin_src haskell
-- It is a good example of deriving a typeclass from another typeclass
class (Functor f) => Applicative f where
    pure :: a -> f a
    (<*>) :: f (a -> b) -> f a -> f b
#+end_src

/Because Haskell has a very good type system and because everything a function can do is take some parameters and return some value, we can tell a lot from a type declaration and this is no exception/. It starts the definition of the =Applicative= class and it also introduces a class constraint. It says that if we want to make a type constructor part of the =Applicative= typeclass, it has to be in =Functor= first. That's why if we know that if a type constructor is part of the =Applicative= typeclass, it's also in =Functor=, so we can use =fmap= on it.

A better way of thinking about =pure= would be to say that /it takes a value and puts it in some sort of default (or pure) context/ — a minimal context that still yields that value. Whereas =fmap= takes a function and a functor and applies the function inside the functor, =<*>= has a type declaration of =f (a -> b) -> f a -> f b=, which looks similar to =fmap :: (a -> b) -> f a -> f b=. It /takes a functor that has a function in it and another functor and sort of extracts that function from the first functor and then maps it over the second one/. When I say *extract*, I actually sort of mean /run/ and then /extract/, maybe even /sequence/.

Use =pure= if you're dealing with =Maybe= values in an applicative context (i.e. using them with =<*>=), otherwise stick to =Just=, Applicative functors and the applicative style of doing =pure f <*> x <*> y <*> ...= allow us to /take a function that expects parameters that aren't necessarily wrapped in functors and use that function to operate on several values that are in functor contexts/ (it basically gets rid of the limitation imposed to the functor that it could only have functions with one parameter). *The function can take as many parameters as we want, because it's always partially applied step by step between occurences of =<*>=*. This becomes even more handy and apparent if we consider the fact that =pure f <*> x= equals =fmap f x=. This is one of the applicative laws. *=pure= puts a value in a default context*. /If we just put a function in a default context and then extract and apply it to a value inside another applicative functor, we did the same as just mapping that function over that applicative functor/. Instead of writing =pure f <*> x <*> y <*> ...=, we can write =fmap f x <*> y <*> ....= This is why =Control.Applicative= exports a function called =<$>=, /which is just =fmap= as an infix operator/. By using =<$>=, the applicative style really shines, because now if we want to apply a function f between three applicative functors, we can write =f <$> x <*> y <*> z=. If the parameters weren't applicative functors but normal values, we'd write =f x y z=.

#+begin_src haskell
(<$>) :: (Functor f) => (a -> b) -> f a -> f b
f <$> x = fmap f x

-- example
λ> map (\x -> x * 2) [1..10]
[2,4,6,8,10,12,14,16,18,20]

λ> (\x -> x * 2) <$> [1..10]
[2,4,6,8,10,12,14,16,18,20]

λ> pure (\x -> x * 2) <*> [1..10]
[2,4,6,8,10,12,14,16,18,20]
#+end_src

There are some more useful examples for =<*>=

#+begin_src haskell
ghci> [(*0),(+100),(^2)] <*> [1,2,3]
[0,0,0,101,102,103,1,4,9]

ghci> [(+),(*)] <*> [1,2] <*> [3,4]
[4,5,5,6,3,4,6,8]

ghci> (*) <$> [2,5,10] <*> [8,10,11]
[16,20,22,40,50,55,80,100,110]

ghci> filter (>50) $ (*) <$> [2,5,10] <*> [8,10,11]
[55,80,100,110]
#+end_src

To use a normal function on applicative functors, just sprinkle some =<$>= and =<*>= about and the function will operate on applicatives and return an applicative. If you ever find yourself binding some I/O actions to names and then calling some function on them and presenting that as the result by using return, consider using the applicative style because it's arguably a bit more concise and terse. (NO, it is NOT. It is killing me..)

#+begin_src haskell
instance Applicative IO where
    pure = return
    a <*> b = do
        f <- a
        x <- b
        return (f x)

main = do
    a <- (++) <$> getLine <*> getLine
    putStrLn $ "The two lines concatenated turn out to be: " ++ a
#+end_src

#+begin_quote
Functor is a derivative from its strict version map. It can apply a function to any computational context, including tree or any customized data structure.  The applicative functor is a functor with more "powerful" tools (functions) to define the default context (=pure=) and to partially apply a function repeatedly to a computational context (=<*>=). In other words, the monad that I've learned so far is all about "computational context".
#+end_quote

You can think of functions as boxes (they are indeed "/computational context/") that contain their eventual results, so doing =k <$> f <*> g= creates a function that will call =k= with the eventual results from =f= and =g=.

In conclusion, applicative functors aren't just interesting, they're also useful, because they allow us to combine different computations, such as I/O computations, non-deterministic computations, computations that might have failed, etc. by using the applicative style. Just by using =<$>= and =<*>= we can use normal functions to uniformly operate on any number of applicative functors and take advantage of the semantics of each one.
