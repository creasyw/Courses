* Functors, Applicative Functors and Monoids

** Functors redux

/Haskell's combination of purity, higher order functions, parameterized algebraic data types, and typeclasses allows us to implement polymorphism on a much higher level than possible in other languages/. *Typeclasses are open*, which means that we can define our own data type, think about what it can act like and connect it with the typeclasses that define its behaviors. Because of that and because of Haskell's great type system that allows us to know a lot about a function just by knowing its type declaration, /we can define typeclasses that define behavior that's very general and abstract/. (Right... _*everything starts from a typeclass*_)

_Functors are things that can be mapped over_, like lists, =Maybe= s, trees, and such. In Haskell, they're described by the typeclass Functor, which has only one typeclass method, namely =fmap=, which has a type of =fmap :: (a -> b) -> f a -> f b=. It says:

1. give me a function that takes an =a= and returns a =b=, and
2. a box with an =a= (or several of them) inside it and I'll give you a box with a =b= (or several of them) inside it.

It kind of /applies the function to the element inside the box/. A more correct term for what a functor is would be /computational context/. The context might be that the computation can have a value or it might have failed (Maybe and Either a) or that there might be more values (lists), stuff like that.

#+begin_src haskell
-- the =f= is the "computational context" mentioned above.
-- it means: the functor towards a context is that it receives a function
-- derives =a= to =b=, so that the context with =a= in it becomes the context
-- with =b= in it
λ> :t fmap
fmap :: Functor f => (a -> b) -> f a -> f b
#+end_src


(_this is something that might be wrong_... the reason we want to make a type constructor an instance of Functor is to make this constructor a "computational context" that can be extracted by =fmap= so that the construction can be re-applied from =a= to =b=. That is, if we've had the new type that is contructed with basic type =a=, then =fmap= comes handy to make the same construction with =b= along with some internal relationship that we want to impose as =(a -> b)=.)

If we want to make a type constructor an instance of =Functor=, it has to have a kind of =* -> *=, which means that it /has to take exactly one concrete type as a type parameter/. For example, =Maybe= can be made an instance because it takes one type parameter to produce a concrete type, like =Maybe Int= or =Maybe String=. If a type constructor takes two parameters, like =Either=, we have to /partially apply the type constructor until it only takes one type parameter/. So we can only write =instance Functor (Either a) where= and then if we imagine that =fmap= is only for =Either a=, it would have a type declaration of =fmap :: (b -> c) -> Either a b -> Either a c=.

#+begin_src haskell
instance Functor IO where
    fmap f action = do
        result <- action
        return (f result)
#+end_src

The result of mapping something over an I/O action will be an I/O action, so right off the bat we use =do= syntax to glue two actions and make a new one. In the implementation for =fmap=, we make a new I/O action that first performs the original I/O action and calls its result =result=. Then, we do =return (f result)=. =return= is a function that /makes an I/O action that doesn't do anything but only presents something as its result/. (In other words, =fmap= is the way for Haskell to get around the inpurity of I/O to apply a "pure" function to the data within the "inpure" I/O box.)

If we look at what =fmap='s type would be if it were limited to =IO=, it would be =fmap :: (a -> b) -> IO a -> IO b=. =fmap= takes a function and an I/O action and returns a new I/O action that's like the old one, except that the function is applied to its contained result. /If you ever find yourself binding the result of an I/O action to a name, only to apply a function to that and call that something else/ (yes, it almost killed me...), consider using =fmap=, because it looks *prettier* (seriously?). If you want to apply multiple transformations to some data inside a functor, /you can declare your own function at the top level/, make a lambda function or ideally, use function composition.

#+begin_src haskell
import Data.Char
import Data.List

-- this is actually another way to abstract the "pure" function out of the impure IO action
main = do line <- fmap (intersperse '-' . reverse . map toUpper) getLine
          putStrLn line
#+end_src

#+begin_src haskell
instance Functor ((->) r) where
    fmap f g = (\x -> f (g x))
#+end_src

What we get now is =fmap :: (a -> b) -> (r -> a) -> (r -> b)=. /Mapping one function over a function has to produce a function/, just like mapping a function over a =Maybe= has to produce a =Maybe= and mapping a function over a list has to produce a list. What does the type =fmap :: (a -> b) -> (r -> a) -> (r -> b)= for this instance tell us? Well, we see that it takes a function from =a= to =b= and a function from =r= to =a= and returns a function from =r= to =b=. /It is the same as Function composition/! We pipe the output of =r -> a= into the input of =a -> b= to get a function =r -> b=, (It also means the second function =r -> a= first applies to the input variable, which is missing in this signature, and then =a -> b= applies. /It also means we can use function to apply not only to data but also to another function/. And, *it also means the function composition =.= is a functor*.

You can think of =fmap= as either _a function that takes a function and a functor and then maps that function over the functor_, or you can think of it as _a function that takes a function and lifts that function so that it operates on functors_. Both views are correct and in Haskell, equivalent.

*Functor laws* (what can be categorized as "computational context"):

1. /Persistency (immutability)/: if we map the =id= function over a functor, the functor that we get back should be the same as the original functor. (the context does not change after applying a function)
2. /Accept function composition/: composing two functions and then mapping the resulting function over a functor should be the same as first mapping one function over the functor and then mapping the other one. Formally written, that means that =fmap (f . g) = fmap f . fmap g=. Or to write it in another way, for any functor =F=, the following should hold: =fmap (f . g) F = fmap f (fmap g F)=. (the sequence of the functions has no effect on the context that they apply to)

/Functions in Haskell are curried by default/, which means that a function that seems to take several parameters actually takes just one parameter and returns a function that takes the next parameter and so on. This mechanism is what enables us to partially apply functions by just calling them with too few parameters, which results in functions that we can then pass on to other functions. /Normal functors support mapping normal functions over existing functors. What if we want to take out the function from a curried functor and then map it to another functor/. In other words, with normal functors, you can just map a function over a functor and then you can't get the result out in any general way, /even if the result is a partially applied function/. Applicative functors, on the other hand, /allow you to operate on several functors with a single function/.

If we know that a type obeys both laws, we can make certain assumptions about how it will act. /If a type obeys the functor laws, we know that calling fmap on a value of that type will only map the function over it, nothing more/. *This leads to code that is more abstract and extensible*, because we can use laws to /reason about behaviors that any functor should have and make functions that operate reliably on any functor/ (these are two main concerns as well as advantages of this language mentioned throughout the book).

** Applicative functors

=Applicative= typeclass, which lies in the =Control.Applicative= module, comes into picture for it. It defines two methods, =pure= and =<*>=. It doesn't provide a default implementation for any of them, so we have to define them both if we want something to be an applicative functor. (this is really sick...)

#+begin_src haskell
ghci> let a = fmap (*) [1,2,3,4]
ghci> :t a
a :: [Integer -> Integer]
ghci> fmap (\f -> f 9) a
[9,18,27,36]
#+end_src

#+begin_src haskell
-- It is a good example of deriving a typeclass from another typeclass
class (Functor f) => Applicative f where
    pure :: a -> f a
    (<*>) :: f (a -> b) -> f a -> f b
#+end_src

/Because Haskell has a very good type system and because everything a function can do is take some parameters and return some value, we can tell a lot from a type declaration and this is no exception/. It starts the definition of the =Applicative= class and it also introduces a class constraint. It says that if we want to make a type constructor part of the =Applicative= typeclass, it has to be in =Functor= first. That's why if we know that if a type constructor is part of the =Applicative= typeclass, it's also in =Functor=, so we can use =fmap= on it.

A better way of thinking about =pure= would be to say that /it takes a value and puts it in some sort of default (or pure) context/ — a minimal context that still yields that value. Whereas =fmap= takes a function and a functor and applies the function inside the functor, =<*>= has a type declaration of =f (a -> b) -> f a -> f b=, which looks similar to =fmap :: (a -> b) -> f a -> f b=. It /takes a functor that has a function in it and another functor and sort of extracts that function from the first functor and then maps it over the second one/. When I say *extract*, I actually sort of mean /run/ and then /extract/, maybe even /sequence/.

Use =pure= if you're dealing with =Maybe= values in an applicative context (i.e. using them with =<*>=), otherwise stick to =Just=, Applicative functors and the applicative style of doing =pure f <*> x <*> y <*> ...= allow us to /take a function that expects parameters that aren't necessarily wrapped in functors and use that function to operate on several values that are in functor contexts/ (it basically gets rid of the limitation imposed to the functor that it could only have functions with one parameter). *The function can take as many parameters as we want, because it's always partially applied step by step between occurences of =<*>=*. This becomes even more handy and apparent if we consider the fact that =pure f <*> x= equals =fmap f x=. This is one of the applicative laws. *=pure= puts a value in a default context*. /If we just put a function in a default context and then extract and apply it to a value inside another applicative functor, we did the same as just mapping that function over that applicative functor/. Instead of writing =pure f <*> x <*> y <*> ...=, we can write =fmap f x <*> y <*> ....= This is why =Control.Applicative= exports a function called =<$>=, /which is just =fmap= as an infix operator/. By using =<$>=, the applicative style really shines, because now if we want to apply a function f between three applicative functors, we can write =f <$> x <*> y <*> z=. If the parameters weren't applicative functors but normal values, we'd write =f x y z=.

#+begin_src haskell
(<$>) :: (Functor f) => (a -> b) -> f a -> f b
f <$> x = fmap f x

-- example
λ> map (\x -> x * 2) [1..10]
[2,4,6,8,10,12,14,16,18,20]

λ> (\x -> x * 2) <$> [1..10]
[2,4,6,8,10,12,14,16,18,20]

λ> pure (\x -> x * 2) <*> [1..10]
[2,4,6,8,10,12,14,16,18,20]
#+end_src

There are some more useful examples for =<*>=

#+begin_src haskell
ghci> [(*0),(+100),(^2)] <*> [1,2,3]
[0,0,0,101,102,103,1,4,9]

ghci> [(+),(*)] <*> [1,2] <*> [3,4]
[4,5,5,6,3,4,6,8]

ghci> (*) <$> [2,5,10] <*> [8,10,11]
[16,20,22,40,50,55,80,100,110]

ghci> filter (>50) $ (*) <$> [2,5,10] <*> [8,10,11]
[55,80,100,110]
#+end_src

To use a normal function on applicative functors, just sprinkle some =<$>= and =<*>= about and the function will operate on applicatives and return an applicative. If you ever find yourself binding some I/O actions to names and then calling some function on them and presenting that as the result by using return, consider using the applicative style because it's arguably a bit more concise and terse. (NO, it is NOT. It is killing me..)

#+begin_src haskell
instance Applicative IO where
    pure = return
    a <*> b = do
        f <- a
        x <- b
        return (f x)

main = do
    a <- (++) <$> getLine <*> getLine
    putStrLn $ "The two lines concatenated turn out to be: " ++ a
#+end_src

#+begin_quote
Functor is a derivative from its strict version map. It can apply a function to any computational context, including tree or any customized data structure.  The applicative functor is a functor with more "powerful" tools (functions) to define the default context (=pure=) and to partially apply a function repeatedly to a computational context (=<*>=). In other words, the monad that I've learned so far is all about "computational context".
#+end_quote

You can think of functions as boxes (they are indeed "/computational context/") that contain their eventual results, so doing =k <$> f <*> g= creates a function that will call =k= with the eventual results from =f= and =g=.

In conclusion, applicative functors aren't just interesting, they're also useful, because they allow us to combine different computations, such as I/O computations, non-deterministic computations, computations that might have failed, etc. by using the applicative style. Just by using =<$>= and =<*>= we can use normal functions to uniformly operate on any number of applicative functors and take advantage of the semantics of each one.
