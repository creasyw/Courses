* Input and Output

Whereas in imperative languages you usually get things done by giving the computer a series of steps to execute, /functional programming is more of defining what stuff is/. /The only thing a function can do in Haskell is give us back some result based on the parameters we gave it/. While functions being unable to change state is good because it helps us reason about our programs, there's one problem with that. (I guess it is the same reason that everything about the I/O operatin is weird...) Haskell actually has a really clever system for dealing with functions that have side-effects that neatly separates the part of our program that is pure and the part of our program that is impure, which does all the dirty work like talking to the keyboard and the screen. With those two parts separated, we can still reason about our pure program and take advantage of all the things that purity offers, like laziness, robustness and modularity while efficiently communicating with the outside world.

#+begin_src haskell
ghci> :t putStrLn
putStrLn :: String -> IO ()
ghci> :t putStrLn "hello, world"
putStrLn "hello, world" :: IO ()
#+end_src

An I/O action is something that, when performed, will carry out an action with a side-effect (that's usually either reading from the input or printing stuff to the screen) and will also contain some kind of return value inside it. Printing a string to the terminal doesn't really have any kind of meaningful return value, so a dummy value of =()= is used.

If we're taking data out of an I/O action, we can only take it out when we're inside another I/O action. This is how Haskell manages to neatly separate the pure and impure parts of our code. =getLine= is in a sense impure because its result value is not guaranteed to be the same when performed twice. That's why it's sort of tainted with the IO type constructor and we can only get that data out in I/O code. And /because I/O code is tainted too, any computation that depends on tainted I/O data will have a tainted result/. If we want to deal with impure data, we have to do it in an impure environment. So the taint of impurity spreads around much like the undead scourge and *it's in our best interest to keep the I/O parts of our code as small as possible*.

Remember, *to get the value out of an I/O action, you have to perform it inside another I/O action by binding it to a name with =<-=*.

/I/O actions will only be performed when they are given a name of main or when they're inside a bigger I/O action that we composed with a do block/. We can also use a do block to glue together a few I/O actions and then we can use that I/O action in another do block and so on. *Either way, they'll be performed only if they eventually fall into main* (this really fucks up things).

#+begin_src haskell
import Data.Char

main = do
    putStrLn "What's your first name?"
    -- bind the IO String to a regular String
    firstName <- getLine
    -- bind the IO String to a regular String
    putStrLn "What's your last name?"
    lastName <- getLine
    -- operations using pure functions with pure data type to get another pure data type
    let bigFirstName = map toUpper firstName
        bigLastName = map toUpper lastName
    -- feed the pure data types into another IO function
    putStrLn $ "hey " ++ bigFirstName ++ " " ++ bigLastName ++ ", how are you?"
#+end_src

=<-= is (for now) for performing I/O actions and binding their results to names. =map toUpper firstName=, however, isn't an I/O action. It's a /pure/ expression in Haskell. So use =<-= when you want to bind results of I/O actions to names and you can use let bindings to bind pure expressions to names. Had we done something like =let firstName = getLine=, we would have just called the =getLine= I/O action a different name and we'd still have to run it through a =<-= to perform it.

*The return in Haskell is really nothing like the return in most other languages*. In Haskell (in I/O actions specifically), it makes an I/O action out of a pure value. If you think about the box analogy from before, it takes a value and wraps it up in a box. The resulting I/O action doesn't actually do anything, it just has that value encapsulated as its result. So in an I/O context, =return "haha"= will have a type of =IO String=, because we needed some I/O action to carry out in the case of an empty input line. That's why we just made a bogus I/O action that doesn't do anything by writing =return ()=. (so, is it like =yield= for I/O?...) Using =return= doesn't cause the I/O do block to end in execution or anything like that.

=print= takes a value of any type that's an instance of =Show= (meaning that we know how to represent it as a string), calls =show= with that value to stringify it and then outputs that string to the terminal. Basically, it's just =putStrLn . show=. It first runs =show= on a value and then feeds that to =putStrLn=, which returns an I/O action that will print out our value.

The =when= function is found in =Control.Monad= (to get access to it, do =import Control.Monad=). It's interesting because in a do block it looks like a control flow statement, but it's actually a normal function. It takes a boolean value and an I/O action if that boolean value is =True=, it returns the same I/O action that we supplied to it. However, if it's =False=, it returns the =return ()= action, so an I/O action that doesn't do anything.

#+begin_src haskell
import Control.Monad

main = do
    c <- getChar
    when (c /= ' ') $ do
        putChar c
        main
#+end_src

#+begin_src haskell
import Control.Monad

main = do
    -- forM get a list of IO (Monad) types of data.
    -- We can also use =mapM=. =forM= is for readability. It puts the function in the end of the block
    -- Note that =forM= expects ONE anonymous function, that's why another =do= is here to chain multiple IO commands
    colors <- forM [1,2,3,4] (\a -> do
        putStrLn $ "Which color do you associate with the number " ++ show a ++ "?"
        color <- getLine
        -- return change the pure data type into an IO type
        return color)
    putStrLn "The colors that you associate with 1, 2, 3 and 4 are: "
    mapM putStrLn colors
#+end_src

I/O actions are values much like any other value in Haskell. We can pass them as parameters to functions and functions can return I/O actions as results. What's special about them is that if they fall into the main function (or are the result in a GHCI line), they are performed. Each I/O action can also encapsulate a result with which it tells you what it got from the real world.

** File and Streams

   #+begin_src haskell
main = interact $ unlines . filter ((<10) . length) . lines
   #+end_src

=interact= can be used to make programs that are piped some contents into them and then dump some result out or it can be used to make programs that appear to take a line of input from the user, give back some result based on that line and then take another line and so on. There isn't actually a real distinction between the two, it just depends on how the user is supposed to use them. (It feels really like a saver - as long as the concatenated function has a signature of =String -> String=, it can be used with the =interact=. As a result, the heavy-lifting operations can all be positioned in a purely functional environment.)

=hGetContents= takes a =Handle=, so it knows which file to get the contents from and returns an =IO String= — an I/O action that holds as its result the contents of the file. This function is pretty much like =getContents=. The only difference is that =getContents= will automatically read from the standard input (that is from the terminal), whereas =hGetContents= takes a file handle which tells it which file to read from. In all other respects, they work the same. And just like =getContents=, =hGetContents= won't attempt to read the file at once and store it in memory, but it will read it as needed. That's really cool because we can treat contents as the whole contents of the file, but it's not really loaded in memory. So if this were a really huge file, doing =hGetContents= wouldn't choke up our memory, but it would read only what it needed to from the file, when it needed to.

We can also use =hFlush=, which is a function that takes a handle and returns an I/O action that will flush the buffer of the file associated with the handle. When we're doing line-buffering, the buffer is flushed after every line. When we're doing block-buffering, it's after we've read a chunk. It's also flushed after closing a handle. That means that when we've reached a newline character, the reading (or writing) mechanism reports all the data so far. But we can use =hFlush= to force that reporting of data that has been read so far. After flushing, the data is available to other programs that are running at the same time.

*Haskell is a pure functional language. What that means is that it has referential transparency. What THAT means is that a function, if given the same parameters twice, must produce the same result twice*. That's really cool because /it allows us to reason differently about programs and it enables us to defer evaluation until we really need it/. However, this makes it a bit tricky for getting random numbers.

/Haskell's laziness allows us to exchange the for and while loops of other languages for filtering and mapping over lists, because evaluation will only happen once it really needs to, so things like infinite lists (and even infinite lists of infinite lists!) are no problem for us/. That's why lists can also be used to represent streams, either when reading from the standard input or when reading from files. We can just open a file and read it as a string, even though it will only be accessed when the need arises.

/Whenever you need better performance in a program that reads a lot of data into strings, give bytestrings a try, chances are you'll get some good performance boosts with very little effort on your part. I usually write programs by using normal strings and then convert them to use bytestrings if the performance is not satisfactory./

Haskell has a very good type system. Algebraic data types allow for types like =Maybe= and =Either= and we can use values of those types to represent results that may be there or not. In C, returning, say, -1 on failure is completely a matter of convention. It only has special meaning to humans. If we're not careful, we might treat these abnormal values as ordinary ones and then they can cause havoc and dismay in our code. Haskell's type system gives us some much-needed safety in that aspect. A function =a -> Maybe b= clearly indicates that it it may produce a =b= wrapped in =Just= or that it may return =Nothing=. The type is different from just plain =a -> b= and if we try to use those two functions interchangeably, the compiler will complain at us.

** Command line arguments

   #+begin_src haskell
import System.Environment
import Data.List

main = do
   args <- getArgs
   progName <- getProgName
   putStrLn "The arguments are:"
   -- the loop can be achieved by either recursion or map/filter
   -- in this case, mapM is the map for the IO operations
   mapM putStrLn args
   putStrLn "The program name is:"
   putStrLn progName
   #+end_src

** Exceptions

Despite having expressive types that support failed computations, Haskell still has support for exceptions, because they make more sense in I/O contexts. A lot of things can go wrong when dealing with the outside world because it is so unreliable.

Earlier, we talked about how we should spend as little time as possible in the I/O part of our program. /The logic of our program should reside mostly within our pure functions, because their results are dependant only on the parameters that the functions are called with/. *When dealing with pure functions, you only have to think about what a function returns, because it can't do anything else*. This makes your life easier. Even though doing some logic in I/O is necessary (like opening files and the like), it should preferably be kept to a minimum. *Pure functions are lazy by default, which means that we don't know when they will be evaluated and that it really shouldn't matter*. However, /once pure functions start throwing exceptions, it matters when they are evaluated. That's why we can only catch exceptions thrown from pure functions in the I/O part of our code/. And that's bad, because we want to keep the I/O part as small as possible. However, if we don't catch them in the I/O part of our code, our program crashes. The solution? *Don't mix exceptions and pure code. Take advantage of Haskell's powerful type system and use types like =Either= and =Maybe= to represent results that may have failed*.

* Functionally Solving Problems

It really helps to first think what the type declaration of a function should be before concerning ourselves with the implementation and then write it down. In Haskell, a function's type declaration tells us a whole lot about the function, due to the very strong type system.

we're going to solve a problem in three steps:

1. Forget Haskell for a minute and think about how we'd solve the problem by hand
2. Think about how we're going to represent our data in Haskell
3. Figure out how to operate on that data in Haskell so that we produce at a solution

* Functors, Applicative Functors and Monoids

** Functors redux

/Haskell's combination of purity, higher order functions, parameterized algebraic data types, and typeclasses allows us to implement polymorphism on a much higher level than possible in other languages/. *Typeclasses are open*, which means that we can define our own data type, think about what it can act like and connect it with the typeclasses that define its behaviors. Because of that and because of Haskell's great type system that allows us to know a lot about a function just by knowing its type declaration, /we can define typeclasses that define behavior that's very general and abstract/. (Right... _*everything starts from a typeclass*_)

_Functors are things that can be mapped over_, like lists, =Maybe= s, trees, and such. In Haskell, they're described by the typeclass Functor, which has only one typeclass method, namely =fmap=, which has a type of =fmap :: (a -> b) -> f a -> f b=. It says:

1. give me a function that takes an =a= and returns a =b=, and
2. a box with an =a= (or several of them) inside it and I'll give you a box with a =b= (or several of them) inside it.

It kind of /applies the function to the element inside the box/. A more correct term for what a functor is would be /computational context/. The context might be that the computation can have a value or it might have failed (Maybe and Either a) or that there might be more values (lists), stuff like that.

#+begin_src haskell
-- the =f= is the "computational context" mentioned above.
-- it means: the functor towards a context is that it receives a function
-- derives =a= to =b=, so that the context with =a= in it becomes the context
-- with =b= in it
λ> :t fmap
fmap :: Functor f => (a -> b) -> f a -> f b
#+end_src


(_this is something that might be wrong_... the reason we want to make a type constructor an instance of Functor is to make this constructor a "computational context" that can be extracted by =fmap= so that the construction can be re-applied from =a= to =b=. That is, if we've had the new type that is contructed with basic type =a=, then =fmap= comes handy to make the same construction with =b= along with some internal relationship that we want to impose as =(a -> b)=.)

If we want to make a type constructor an instance of =Functor=, it has to have a kind of =* -> *=, which means that it /has to take exactly one concrete type as a type parameter/. For example, =Maybe= can be made an instance because it takes one type parameter to produce a concrete type, like =Maybe Int= or =Maybe String=. If a type constructor takes two parameters, like =Either=, we have to /partially apply the type constructor until it only takes one type parameter/. So we can only write =instance Functor (Either a) where= and then if we imagine that =fmap= is only for =Either a=, it would have a type declaration of =fmap :: (b -> c) -> Either a b -> Either a c=.

#+begin_src haskell
instance Functor IO where
    fmap f action = do
        result <- action
        return (f result)
#+end_src

The result of mapping something over an I/O action will be an I/O action, so right off the bat we use =do= syntax to glue two actions and make a new one. In the implementation for =fmap=, we make a new I/O action that first performs the original I/O action and calls its result =result=. Then, we do =return (f result)=. =return= is a function that /makes an I/O action that doesn't do anything but only presents something as its result/. (In other words, =fmap= is the way for Haskell to get around the inpurity of I/O to apply a "pure" function to the data within the "inpure" I/O box.)

If we look at what =fmap='s type would be if it were limited to =IO=, it would be =fmap :: (a -> b) -> IO a -> IO b=. =fmap= takes a function and an I/O action and returns a new I/O action that's like the old one, except that the function is applied to its contained result. /If you ever find yourself binding the result of an I/O action to a name, only to apply a function to that and call that something else/ (yes, it almost killed me...), consider using =fmap=, because it looks *prettier* (seriously?). If you want to apply multiple transformations to some data inside a functor, /you can declare your own function at the top level/, make a lambda function or ideally, use function composition.

#+begin_src haskell
import Data.Char
import Data.List

-- this is actually another way to abstract the "pure" function out of the impure IO action
main = do line <- fmap (intersperse '-' . reverse . map toUpper) getLine
          putStrLn line
#+end_src

#+begin_src haskell
instance Functor ((->) r) where
    fmap f g = (\x -> f (g x))
#+end_src

What we get now is =fmap :: (a -> b) -> (r -> a) -> (r -> b)=. /Mapping one function over a function has to produce a function/, just like mapping a function over a =Maybe= has to produce a =Maybe= and mapping a function over a list has to produce a list. What does the type =fmap :: (a -> b) -> (r -> a) -> (r -> b)= for this instance tell us? Well, we see that it takes a function from =a= to =b= and a function from =r= to =a= and returns a function from =r= to =b=. /It is the same as Function composition/! We pipe the output of =r -> a= into the input of =a -> b= to get a function =r -> b=, (It also means the second function =r -> a= first applies to the input variable, which is missing in this signature, and then =a -> b= applies. /It also means we can use function to apply not only to data but also to another function/. And, *it also means the function composition =.= is a functor*.

You can think of =fmap= as either _a function that takes a function and a functor and then maps that function over the functor_, or you can think of it as _a function that takes a function and lifts that function so that it operates on functors_. Both views are correct and in Haskell, equivalent.

*Functor laws* (what can be categorized as "computational context"):

1. /Persistency (immutability)/: if we map the =id= function over a functor, the functor that we get back should be the same as the original functor. (the context does not change after applying a function)
2. /Accept function composition/: composing two functions and then mapping the resulting function over a functor should be the same as first mapping one function over the functor and then mapping the other one. Formally written, that means that =fmap (f . g) = fmap f . fmap g=. Or to write it in another way, for any functor =F=, the following should hold: =fmap (f . g) F = fmap f (fmap g F)=. (the sequence of the functions has no effect on the context that they apply to)

/Functions in Haskell are curried by default/, which means that a function that seems to take several parameters actually takes just one parameter and returns a function that takes the next parameter and so on. This mechanism is what enables us to partially apply functions by just calling them with too few parameters, which results in functions that we can then pass on to other functions. /Normal functors support mapping normal functions over existing functors. What if we want to take out the function from a curried functor and then map it to another functor/. In other words, with normal functors, you can just map a function over a functor and then you can't get the result out in any general way, /even if the result is a partially applied function/. Applicative functors, on the other hand, /allow you to operate on several functors with a single function/.

If we know that a type obeys both laws, we can make certain assumptions about how it will act. /If a type obeys the functor laws, we know that calling fmap on a value of that type will only map the function over it, nothing more/. *This leads to code that is more abstract and extensible*, because we can use laws to /reason about behaviors that any functor should have and make functions that operate reliably on any functor/ (these are two main concerns as well as advantages of this language mentioned throughout the book).

** Applicative functors

=Applicative= typeclass, which lies in the =Control.Applicative= module, comes into picture for it. It defines two methods, =pure= and =<*>=. It doesn't provide a default implementation for any of them, so we have to define them both if we want something to be an applicative functor. (this is really sick...)

#+begin_src haskell
ghci> let a = fmap (*) [1,2,3,4]
ghci> :t a
a :: [Integer -> Integer]
ghci> fmap (\f -> f 9) a
[9,18,27,36]
#+end_src

#+begin_src haskell
-- It is a good example of deriving a typeclass from another typeclass
class (Functor f) => Applicative f where
    pure :: a -> f a
    (<*>) :: f (a -> b) -> f a -> f b
#+end_src

/Because Haskell has a very good type system and because everything a function can do is take some parameters and return some value, we can tell a lot from a type declaration and this is no exception/. It starts the definition of the =Applicative= class and it also introduces a class constraint. It says that if we want to make a type constructor part of the =Applicative= typeclass, it has to be in =Functor= first. That's why if we know that if a type constructor is part of the =Applicative= typeclass, it's also in =Functor=, so we can use =fmap= on it.

A better way of thinking about =pure= would be to say that /it takes a value and puts it in some sort of default (or pure) context/ — a minimal context that still yields that value. Whereas =fmap= takes a function and a functor and applies the function inside the functor, =<*>= has a type declaration of =f (a -> b) -> f a -> f b=, which looks similar to =fmap :: (a -> b) -> f a -> f b=. It /takes a functor that has a function in it and another functor and sort of extracts that function from the first functor and then maps it over the second one/. When I say *extract*, I actually sort of mean /run/ and then /extract/, maybe even /sequence/.

Use =pure= if you're dealing with =Maybe= values in an applicative context (i.e. using them with =<*>=), otherwise stick to =Just=, Applicative functors and the applicative style of doing =pure f <*> x <*> y <*> ...= allow us to /take a function that expects parameters that aren't necessarily wrapped in functors and use that function to operate on several values that are in functor contexts/ (it basically gets rid of the limitation imposed to the functor that it could only have functions with one parameter). *The function can take as many parameters as we want, because it's always partially applied step by step between occurences of =<*>=*. This becomes even more handy and apparent if we consider the fact that =pure f <*> x= equals =fmap f x=. This is one of the applicative laws. *=pure= puts a value in a default context*. /If we just put a function in a default context and then extract and apply it to a value inside another applicative functor, we did the same as just mapping that function over that applicative functor/. Instead of writing =pure f <*> x <*> y <*> ...=, we can write =fmap f x <*> y <*> ....= This is why =Control.Applicative= exports a function called =<$>=, /which is just =fmap= as an infix operator/. By using =<$>=, the applicative style really shines, because now if we want to apply a function f between three applicative functors, we can write =f <$> x <*> y <*> z=. If the parameters weren't applicative functors but normal values, we'd write =f x y z=.

#+begin_src haskell
(<$>) :: (Functor f) => (a -> b) -> f a -> f b
f <$> x = fmap f x

-- example
λ> map (\x -> x * 2) [1..10]
[2,4,6,8,10,12,14,16,18,20]

λ> (\x -> x * 2) <$> [1..10]
[2,4,6,8,10,12,14,16,18,20]

λ> pure (\x -> x * 2) <*> [1..10]
[2,4,6,8,10,12,14,16,18,20]
#+end_src

There are some more useful examples for =<*>=

#+begin_src haskell
ghci> [(*0),(+100),(^2)] <*> [1,2,3]
[0,0,0,101,102,103,1,4,9]

ghci> [(+),(*)] <*> [1,2] <*> [3,4]
[4,5,5,6,3,4,6,8]

ghci> (*) <$> [2,5,10] <*> [8,10,11]
[16,20,22,40,50,55,80,100,110]

ghci> filter (>50) $ (*) <$> [2,5,10] <*> [8,10,11]
[55,80,100,110]
#+end_src

To use a normal function on applicative functors, just sprinkle some =<$>= and =<*>= about and the function will operate on applicatives and return an applicative. If you ever find yourself binding some I/O actions to names and then calling some function on them and presenting that as the result by using return, consider using the applicative style because it's arguably a bit more concise and terse. (NO, it is NOT. It is killing me..)

#+begin_src haskell
instance Applicative IO where
    pure = return
    a <*> b = do
        f <- a
        x <- b
        return (f x)

main = do
    a <- (++) <$> getLine <*> getLine
    putStrLn $ "The two lines concatenated turn out to be: " ++ a
#+end_src

#+begin_quote
Functor is a derivative from its strict version map. It can apply a function to any computational context, including tree or any customized data structure.  The applicative functor is a functor with more "powerful" tools (functions) to define the default context (=pure=) and to partially apply a function repeatedly to a computational context (=<*>=). In other words, the monad that I've learned so far is all about "computational context".
#+end_quote

You can think of functions as boxes (they are indeed "/computational context/") that contain their eventual results, so doing =k <$> f <*> g= creates a function that will call =k= with the eventual results from =f= and =g=.

In conclusion, applicative functors aren't just interesting, they're also useful, because they allow us to combine different computations, such as I/O computations, non-deterministic computations, computations that might have failed, etc. by using the applicative style. Just by using =<$>= and =<*>= we can use normal functions to uniformly operate on any number of applicative functors and take advantage of the semantics of each one.
