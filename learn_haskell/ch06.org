* Higher order functions

Haskell /functions can take functions as parameters and return functions as return values/. A function that does either of those is called a higher order function. Higher order functions aren't just a part of the Haskell experience, they pretty much are the Haskell experience. It turns out that if you want to define computations by defining what stuff is instead of defining steps that change some state and maybe looping them, higher order functions are indispensable. They're a really powerful way of solving problems and thinking about programs.

/Every function in Haskell officially only takes one parameter/. If we call a function with too few parameters, we get back a partially applied function, meaning a function that takes as many parameters as we left out. Using partial application (calling functions with too few parameters, if you will) is a neat way to create functions on the fly so we can pass them to another function or to seed them with some data. (This is called /Curried functions/. It also means when it comes to function definition, the =->= is always *right-associative*, while the actual function implementation is always *left-associative*. To break these associative patterns, we need to use parathesis.)

The type of =max= is =max :: (Ord a) => a -> a -> a=. That can also be written as =max :: (Ord a) => a -> (a -> a)=. That could be read as: =max= takes an =a= and returns (that's the =->=) =a= function that takes an =a= and returns an =a=. /That's why the return type and the parameters of functions are all simply separated with arrows/.

In functional programming, that pattern is achieved with mapping and filtering. You make a function that takes a value and produces some result. We map that function over a list of values and then we filter the resulting list out for the results that satisfy our search. /Thanks to Haskell's laziness, even if you map something over a list several times and filter it several times, it will only pass over the list once/.

Infix functions can also be partially applied by using sections. To section an infix function, simply surround it with parentheses and only supply a parameter on one side. That creates a function that takes one parameter and then applies it to the side that's missing an operand. An insultingly trivial function:

#+begin_src haskell
divideByTen :: (Floating a) => a -> a
divideByTen = (/10)
#+end_src

Calling, say, =divideByTen 200= is equivalent to doing =200 / 10=, as is doing =(/10) 200=.

/The awesomeness and usefulness of partial application is evident. If our function requires us to pass it a function that takes only one parameter, we can just partially apply a function to the point where it takes only one parameter and then pass it/.

As you can see, a single higher order function can be used in very versatile ways. Imperative programming usually uses stuff like for loops, while loops, setting something to a variable, checking its state, etc. to achieve some behavior and then wrap it around an interface, like a function. Functional programming uses higher order functions to abstract away common patterns, like examining two lists in pairs and doing something with those pairs or getting a set of solutions and eliminating the ones you don't need.

/A side note/ about the type signature of a function. Take =map= and =filter= as examples:

#+begin_src haskell
map :: (a -> b) -> [a] -> [b]
map _ [] = []
map f (x:xs) = f x : map f xs

filter :: (a -> Bool) -> [a] -> [a]
filter _ [] = []
filter p (x:xs)
    | p x       = x : filter p xs
    | otherwise = filter p xs
#+end_src

We don't have to define the type of in the signature for =a= or =b=. It actually makes the function more general..

/Another side note/. The infinite list in a function could serve as infinite loop in an imperative language, as well as an actual infinite list which is the pool for further processing.

Lambdas are basically anonymous functions that are used because we need some functions only once. Normally, we make a lambda with the sole purpose of passing it to a higher-order function. To make a lambda, we write a =\= (because it kind of looks like the greek letter lambda if you squint hard enough) and then we write the parameters, separated by spaces. After that comes a =->= and then the function body. We usually surround them by parentheses, because otherwise they extend all the way to the right.

People who are not well acquainted with /how currying and partial application works/ often use lambdas where they don't need to. For instance, the expressions map (+3) [1,6,3,2] and map (\x -> x + 3) [1,6,3,2] are equivalent since both (+3) and (\x -> x + 3) are functions that take a number and add 3 to it.

The right fold, =foldr= works in a similar way to the left fold, /only the accumulator eats up the values *from the right* /. Also, /the left fold's binary function has the accumulator as the first parameter and the current value as the second one (so =\acc x -> ...=), the right fold's binary function has the current value as the first parameter and the accumulator as the second one (so =\x acc -> ...=)/. It kind of makes sense that the right fold has the accumulator on the right, because it /folds from the right side/. /One big difference/ is that *right folds work on infinite lists*, whereas left ones don't! To put it plainly, if you take an infinite list at some point and you fold it up from the right, you'll eventually reach the beginning of the list. However, if you take an infinite list at a point and you try to fold it up from the left, you'll never reach an end!

*Folds can be used to implement any function where you traverse a list once, element by element, and then return something based on that. Whenever you want to traverse a list to return something, chances are you want a fold*. That's why folds are, along with maps and filters, one of the most useful types of functions in functional programming. The =foldl1= and =foldr1= functions work much like foldl and foldr, only you don't need to provide them with an explicit starting value. They assume the first (or last) element of the list to be the starting value and then start the fold with the element next to it.

=scanl= and =scanr= are like =foldl= and =foldr=, only they report all the intermediate accumulator states in the form of a list. There are also =scanl1= and =scanr1=, which are analogous to =foldl1= and =foldr1=. Scans are used to monitor the progression of a function that can be implemented as a fold.

Whereas normal function application (putting a space between two things) has a really high precedence, the =$= function has the lowest precedence. Function application with a space is *left-associative* (so =f a b c= is the same as =((f a) b) c)=), function application with =$= is *right-associative*.

Apart from getting rid of parentheses, =$= means that /function application (which means the parameter of a function) can be treated just like another function/ (it is also similar to the notion that everything in the FP is data - both parameters and functions are homogeneous in this sense). That way, we can, for instance, map *function application* over a list of functions (this is sick...). /When a =$= is encountered, the expression on its right is applied as the parameter to the function on its left/

#+begin_src haskell
ghci> map ($ 3) [(4+), (10*), (^2), sqrt]
[7.0,30.0,9.0,1.7320508075688772]
#+end_src

To look it more closely, we can see the trick of =$= -

#+begin_src haskell
Prelude> :t 3
3 :: Num p => p
-- it transforms the number to become a parameter in a two-parameters function
Prelude> :t ($ 3)
($ 3) :: Num a => (a -> b) -> b
-- Note that the given parameter following the =$= could be either the first or
-- the second parameter depending on the function that we feed into this function
λ> map ($ 3) [(4+), (10/)]
[7.0,3.3333333333333335]
λ> map ($ 3) [(4+), (/10)]
#+end_src

In Haskell, function composition with the =.= function is defined like so: (this is even sicker)

#+begin_src haskell
(.) :: (b -> c) -> (a -> b) -> a -> c
f . g = \x -> f (g x)
#+end_src

#+begin_src haskell
ghci> map (\x -> negate (abs x)) [5,-3,-6,7,-3,2,-19,24]
[-5,-3,-6,-7,-3,-2,-19,-24]

ghci> map (negate . abs) [5,-3,-6,7,-3,2,-19,24]
[-5,-3,-6,-7,-3,-2,-19,-24]
#+end_src

But what about functions that take several parameters? Well, if we want to use them in function composition, we usually have to partially apply them just so much that each function takes just one parameter. =sum (replicate 5 (max 6.7 8.9))= can be rewritten as =(sum . replicate 5 . max 6.7) 8.9= or as =sum . replicate 5 . max 6.7 $ 8.9=. (This is a good example that by default the function is left-associative, so we don't need to add parathesis to something like =replicate 5=)

Many times, a point-free style is more readable and concise, because /it makes you think about functions and what kind of functions composing them results in instead of thinking about data and how it's shuffled around/. (actually, both perspectives are valluable.) You can take simple functions and use composition as glue to form more complex functions. However, many times, writing a function in point free style can be less readable if a function is too complex. That's why /making long chains of function composition is discouraged/. The prefered style is to *use let bindings to give labels to intermediary results or split the problem into sub-problems and then put it together so that the function makes sense to someone reading it instead of just making a huge composition chain*.
